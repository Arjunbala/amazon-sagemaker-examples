{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horovod fundamentals\n",
    "\n",
    "https://github.com/horovod/horovod#documentation\n",
    "\n",
    "How to convert a single node training script to multi-node.\n",
    "\n",
    "1. Run hvd.init() to initialize Horovod\n",
    "2. Pin each GPU to single process (using local rank)\n",
    "3. Scale learning rate by number of workers (LR is given as part of optimizer)\n",
    "4. Wrap optimizer in hvd.DistributedOptimizer\n",
    "5. Broadcast initial variables from rank 0 to other ranks.\n",
    "6. Save checkpoint only on rank 0 to avoid corruption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of a TF training script using keras\n",
    "\n",
    "# Initialize horovod\n",
    "hvd.init()\n",
    "\n",
    "# Pin process to dedicated GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "keras.backend.set_session(config=config)\n",
    "\n",
    "# Prepare dataset\n",
    "x_train, x_test, y_train, y_test\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(...)\n",
    "\n",
    "# Define optimizer and scale learning rate\n",
    "opt = keras.optimizers.Adadelta(lr * hvd.size())\n",
    "\n",
    "# Add distributed optimizer\n",
    "opt = hvd.DistributedOptimizer(opt, backward_passes_per_step=1)\n",
    "\n",
    "# Tie together the loss function, optimizer, metric, and model\n",
    "model.compile(loss_fn, opt, metrics=['accuracy'])\n",
    "\n",
    "# Custom callbacks during training for broadcasting initial params, checkpointing\n",
    "callbacks = [\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "]\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "if hvd.rank() == 0:\n",
    "    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "    \n",
    "# Start training\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=callbacks,\n",
    "          epochs=epochs,\n",
    "          verbose=1 if hvd.rank() == 0 else 0,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient Net paper\n",
    "https://arxiv.org/pdf/1905.11946.pdf\n",
    "\n",
    "\n",
    "Github link -https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow2/Classification/ConvNets/efficientnet\n",
    "\n",
    "\n",
    "Special Features  -\n",
    "- Mixed precision arithmetic\n",
    "- XLA\n",
    "- cosine decay LR\n",
    "- multi GPU Horovod with NCCL backend\n",
    "- TF 32 in A100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to prepare dataset\n",
    "Use https://github.com/kmonachopoulos/ImageNet-to-TFrecord/blob/master/build_imagenet_data.py to generate TF records\n",
    "python convert.py --train_directory=/balarjun/pytorch/train --validation_directory=/balarjun/pytorch/val\n",
    "Uploaded TF records to s3://smddp-570106654206-us-west-2/dataset/efficient/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up DLC and running Horovod TF training\n",
    "1. Download DLC 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.6.0-gpu-py38-cu112-ubuntu20.04 and extract. Follow our guide https://quip-amazon.com/RGLAANbEf82L#Jfb9AA6x7dX for this.\n",
    "2. Inside fsx, setup code https://github.com/NVIDIA/DeepLearningExamples and download TF records (this will be set as data dir)    \n",
    "3. srun -N 1 nvidia-modprobe -u -c=0\n",
    "3. Login to DLC: srun -N 1 --pty enroot start --rw --root -m /fsx:/fsx pyxis_dlc-tf\n",
    "4. cd /fsx/DeepLearningExamples/TensorFlow2/Classification/ConvNets/efficientnet/\n",
    "5.\n",
    "pip install nvidia-pyindex\n",
    "pip install nvidia-dllogger\n",
    "pip install tensorflow-addons\n",
    "pip install tensorflow-datasets\n",
    "pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110\n",
    "pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110\n",
    "6. python main.py --mode=train --arch=efficientnet-b0 --model_dir=/fsx/ --data_dir=/fsx/efficient-net-data/\n",
    "check that above code can start running\n",
    "7. Running inside container, multi process\n",
    "mpirun --hostfile hostfile -N 8 --tag-output --oversubscribe --allow-run-as-root --mca btl_vader_single_copy_mechanism none--mca btl_tcp_if_exclude lo,docker0 -x PATH=/opt/amazon/openmpi/bin:$PATH -x LD_LIBRARY_PATH=/opt/amazon/openmpi/lib:$LD_LIBRARY_PATH  -x NCCL_DEBUG=INFO -x RDMAV_FORK_SAFE=1 python main.py --mode=train --arch=efficientnet-b0 --model_dir=/fsx/ --data_dir=/fsx/efficient-net-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptation to SM DDP\n",
    "SMDDP adaptation code is at this branch - https://github.com/Arjunbala/DeepLearningExamples/tree/smddp-adapt\n",
    "It has 2 commits. (one main conversion and one some bug fixes)\n",
    "Next, install herring inside TF container. Had to modify build script to remove SMDATAPARALLEL_PT option.\n",
    "\n",
    "Running in distributed mode on EC2 -\n",
    "Needed to do a bunch of hacks to get things working.\n",
    "Remove -c /opt/conda from exec_inside_alloc.sh\n",
    "Got \"Unable to activate conda environment error\" -- removed the exit 1 call and allowed execution to proceed made things work\n",
    "\n",
    "hrun -N 2 --container dlc-tf python /fsx/adaptation/DeepLearningExamples/TensorFlow2/Classification/ConvNets/efficientnet/main.py --mode=train --arch=efficientnet-b0 --model_dir=/fsx/ --data_dir=/fsx/efficient-net-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
